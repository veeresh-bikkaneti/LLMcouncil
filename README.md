<<<<<<< HEAD
# LLMCouncil: Multi-Agent AI Assistant

A production-ready AI support triage system where multiple specialized agents (Vision, Technical, Empathy) analyze queries in parallel, and a Chairperson agent synthesizes their findings into a consensus verdict.

## Architecture

```
User Query + Image
      â†“
   Backend API (Express)
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Orchestration Engine   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vision â”‚ Tech â”‚ Empathy â”‚  â† Parallel Execution
â”‚ GPT-4o â”‚Claudeâ”‚ Gemini  â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Chairperson (GPT-4)  â”‚  â† Synthesis
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
  Consensus Report
```

## Quick Start

### Prerequisites
- Node.js 18+
- Docker & Docker Compose
- PostgreSQL (via Docker)
- API Keys: Google AI, OpenAI, Anthropic

### 1. Environment Setup

```bash
# Navigate to server directory
cd server

# Copy environment template
cp .env.local .env.local

# Edit .env.local and add your API keys:
# - GOOGLE_API_KEY
# - OPENAI_API_KEY
# - ANTHROPIC_API_KEY
# - JWT_SECRET (generate with: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))")
```

### 2. Database Setup (Docker)

```bash
# From project root
docker-compose up -d postgres

# Wait for database to be ready
docker-compose logs postgres

# The schema will be automatically initialized from server/src/db/schema.sql
```

### 3. Start Backend

**Option A: Docker (Recommended)**
```bash
docker-compose up
```

**Option B: Local Development**
```bash
cd server
npm install
npm run dev
```

Server will start on `http://localhost:3001`

### 4. Verify Installation

```bash
# Health check
curl http://localhost:3001/health

# Expected response:
# {"status":"ok","timestamp":"...","environment":"development"}
```

## API Endpoints

### Authentication

#### POST /auth/register
Register a new user.
```json
{
  "email": "user@example.com",
  "password": "securepassword"
}
```

Response:
```json
{
  "status": "success",
  "token": "jwt-token-here",
  "userId": "uuid"
}
```

#### POST /auth/login
```json
{
  "email": "user@example.com",
  "password": "securepassword"
}
```

### Analysis

#### POST /api/analyze
Submit a query for council analysis.

Headers:
```
Authorization: Bearer {jwt-token}
Content-Type: multipart/form-data
```

Body:
```
query: "User cannot login to the application"
image: [file] (optional)
```

Response:
```json
{
  "status": "processing",
  "reportId": "uuid",
  "message": "Analysis started. Poll /api/results/{reportId} for updates."
}
```

#### GET /api/results/:reportId
Poll for analysis results.

Response (pending):
```json
{
  "status": "pending",
  "report": { ... }
}
```

Response (complete):
```json
{
  "status": "complete",
  "report": {
    "id": "uuid",
    "priority_score": 8,
    "root_cause": "...",
    "recommended_action": "...",
    "consensus_rate": 0.87,
    "agentOutputs": [...]
  }
}
```

### History

#### GET /api/history?limit=50&offset=0
Get analysis history.

#### GET /api/analytics
Get user analytics (total analyses, costs, etc).

## Project Structure

```
LLMCouncil/
â”œâ”€â”€ server/                 # Backend (Node.js/Express)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ agents/        # AI Agent implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ vision.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ technical.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ empathy.ts
â”‚   â”‚   â”‚   â””â”€â”€ chairperson.ts
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ orchestration.ts
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â””â”€â”€ schema.sql
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ .env.local         # Your API keys (DO NOT COMMIT)
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ llmcouncil_-ai-assistant-suite/  # Frontend (React)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## Development

### Running Tests
```bash
cd server
npm test
```

### Database Migrations
```bash
# Manual schema update
psql -d llmcouncil -f server/src/db/schema.sql
```

### Debugging
```bash
# View logs
docker-compose logs -f backend
docker-compose logs -f postgres
```

## Production Deployment

See `llmcouncil_prod_spec.md` for full production deployment guide.

Key considerations:
- Use environment-specific `.env` files
- Enable HTTPS
- Configure rate limiting
- Set up monitoring (Datadog/Sentry)
- Database backups
- Load testing (target: 1000 concurrent users)

## Security

- API keys are stored encrypted (AES-256)
- JWT authentication for all endpoints
- Rate limiting enabled (60 req/min by default)
- PII detection in input validation
- SQL injection protection via parameterized queries

## License

Proprietary - Internal Use Only

## Support

For issues or questions, refer to:
- `llmcouncil_prod_spec.md` - Full technical specification
- `PROJECT_STATUS_REPORT.md` - Current implementation status
- `walkthrough.md` - Latest verification results
=======
# LLM Council - VS Code Extension

Multi-agent AI analysis directly in VS Code using GitHub Copilot's authentication.

## Features

- ðŸ¤– **Parallel Agent Execution** - Vision, Technical, and Empathy agents analyze simultaneously
- ðŸ” **GitHub Copilot Integration** - Uses existing Copilot authentication
- âš¡ **Fast Results** - Parallel execution provides comprehensive analysis in seconds
- ðŸ“Š **Live Updates** - Real-time progress tracking for each agent
- ðŸ“ **Export to Markdown** - Save analysis reports

## Usage

**Analyze Selected Text:**
- Select text â†’ Press `Ctrl+Shift+L` (Windows/Linux) or `Cmd+Shift+L` (Mac)
- Or right-click â†’ "LLMCouncil: Analyze Selection"

**Open Council Panel:**
- Command Palette â†’ "LLMCouncil: Open Council Panel"

## Requirements

- **GitHub Copilot** extension (for automatic authentication)
- OR manually configure API keys in VS Code Settings

## Extension Settings

- `llmcouncil.preferredModel` - Preferred language model (default: auto)
- `llmcouncil.enableParallelExecution` - Enable parallel execution (default: true)

## Installation

### From VSIX
```bash
code --install-extension llmcouncil-vscode-0.1.0.vsix
```

### Development
```bash
cd llmcouncil-vscode
npm install
npm run compile
```
Press `F5` to launch Extension Development Host

## How It Works

**Agent Roles:**
- **Vision Agent** - Analyzes visual aspects, UI/UX issues
- **Technical Librarian** - Searches for technical solutions
- **Empathy Analyst** - Assesses user sentiment and urgency
- **Chairperson** - Synthesizes all perspectives into final verdict

**Architecture:**
- Uses VS Code Language Model API (`vscode.lm`)
- Automatically detects GitHub Copilot models
- Falls back to manual API keys if needed
- Parallel execution for speed

## License

MIT
>>>>>>> 13d05ff493236b65c8ac7413e031d2bc848efd02
